{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('/home/aiteam/tykim/cubox/diffusers/src')\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l =[99, 999]\n",
    "d= {'asd': 10, 'b': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mitems:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(a, b)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not iterable"
     ]
    }
   ],
   "source": [
    "for a, b in d.items:\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(l, d):\n",
    "    print(d[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.diffusers.models.unet_2d_blocks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.diffusers.models.activations import get_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxDecoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 up_block_types = [\"UpDecoderBlockTimeless2D\", \"AttnUpDecoderBlockTimeless2D\", \"UpDecoderBlockTimeless2D\"],\n",
    "                 block_out_channels = [64, 128, 256, 512],\n",
    "                 layers_per_block = 2,\n",
    "                 norm_eps: float = 1e-5,\n",
    "                 act_fn: str = \"silu\",\n",
    "                 norm_num_groups: int = 32,\n",
    "                 attention_head_dim: Optional[int] = 8,\n",
    "                 start_spatial_dim = 32,\n",
    "                 end_spatial_dim = 256,\n",
    "                 final_outchannel = 3\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        reversed_block_out_channels = list(reversed(block_out_channels)) # [512, 256, 128, 64]\n",
    "        self.up_blocks = nn.ModuleList([])\n",
    "\n",
    "        num_upsamples = int(np.log2(end_spatial_dim // start_spatial_dim))\n",
    "        upsample_flags = [True] * num_upsamples + [False] * (len(up_block_types) - num_upsamples)\n",
    "\n",
    "        for i, up_block_type in enumerate(up_block_types):\n",
    "            input_channel = reversed_block_out_channels[i]\n",
    "            output_channel = reversed_block_out_channels[min(i + 1, len(block_out_channels) - 1)]\n",
    "\n",
    "            up_block = get_up_block(\n",
    "                up_block_type,\n",
    "                num_layers=layers_per_block + 1,\n",
    "                in_channels=input_channel,\n",
    "                out_channels=output_channel,\n",
    "                prev_output_channel = None,\n",
    "                temb_channels = None,\n",
    "                add_upsample=upsample_flags[i],\n",
    "                resnet_eps=norm_eps,\n",
    "                resnet_act_fn=act_fn,\n",
    "                resnet_groups=norm_num_groups,\n",
    "                attention_head_dim=attention_head_dim if attention_head_dim is not None else output_channel,\n",
    "            )\n",
    "            self.up_blocks.append(up_block)\n",
    "\n",
    "        # out\n",
    "        if norm_num_groups is not None:\n",
    "            self.conv_norm_out = nn.GroupNorm(\n",
    "                num_channels=block_out_channels[0], num_groups=norm_num_groups, eps=norm_eps\n",
    "            )\n",
    "\n",
    "            self.conv_act = get_activation(act_fn)\n",
    "\n",
    "        else:\n",
    "            self.conv_norm_out = None\n",
    "            self.conv_act = None\n",
    "            \n",
    "        conv_out_kernel = 3\n",
    "\n",
    "        conv_out_padding = (conv_out_kernel - 1) // 2\n",
    "        self.conv_out = nn.Conv2d(\n",
    "            block_out_channels[0], final_outchannel, kernel_size=conv_out_kernel, padding=conv_out_padding\n",
    "        )\n",
    "    def forward(self,\n",
    "                sample: torch.FloatTensor,\n",
    "                return_dict: bool = True):\n",
    "        for upsample_block in self.up_blocks:\n",
    "            sample = upsample_block(sample)\n",
    "        if self.conv_norm_out:\n",
    "            sample = self.conv_norm_out(sample)\n",
    "            sample = self.conv_act(sample)\n",
    "        sample = self.conv_out(sample)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sample,)\n",
    "\n",
    "        return sample\n",
    "        #return UNet2DConditionOutput(sample=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad =AuxDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad(torch.randn(1, 512, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): UpDecoderBlockTimeless2D(\n",
       "    (resnets): ModuleList(\n",
       "      (0): ResnetBlockTimeless2D(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "        (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x ResnetBlockTimeless2D(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (upsamplers): ModuleList(\n",
       "      (0): Upsample2D(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): AttnUpDecoderBlockTimeless2D(\n",
       "    (attentions): ModuleList(\n",
       "      (0-2): 3 x Attention(\n",
       "        (group_norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (to_out): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0): ResnetBlockTimeless2D(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "        (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x ResnetBlockTimeless2D(\n",
       "        (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (upsamplers): ModuleList(\n",
       "      (0): Upsample2D(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): UpDecoderBlockTimeless2D(\n",
       "    (resnets): ModuleList(\n",
       "      (0-2): 3 x ResnetBlockTimeless2D(\n",
       "        (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (upsamplers): ModuleList(\n",
       "      (0): Upsample2D(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad.up_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad =AuxDecoder(block_out_channels = [64, 128, 256],\n",
    "               up_block_types = [\"UpDecoderBlockTimeless2D\", \"UpDecoderBlockTimeless2D\", \"UpDecoderBlockTimeless2D\"],\n",
    "               start_spatial_dim = 128,\n",
    "               end_spatial_dim = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad(torch.randn(1, 256, 128, 128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad =AuxDecoder(block_out_channels = [64, 128, 256],\n",
    "               up_block_types = [\"UpDecoderBlockTimeless2D\", \"UpDecoderBlockTimeless2D\", \"UpDecoderBlockTimeless2D\"],\n",
    "               start_spatial_dim = 128,\n",
    "               end_spatial_dim = 256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
